{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "!pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: ipynb in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (5.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (1.20.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2020.1)\n",
      "Requirement already satisfied: six in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from plotly->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from plotly->-r requirements.txt (line 4)) (8.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (2020.6.8)\n",
      "Requirement already satisfied: click in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alxau\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 5)) (4.47.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# from .full.Gensim_Doc_Modelling import *\r\n",
    "# import ipynb.fs.defs.Topic_Analysis\r\n",
    "\r\n",
    "from gsdmm_master.gsdmm import MovieGroupProcess\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
    "from collections import Counter\r\n",
    "\r\n",
    "\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import TweetTokenizer\r\n",
    "from matplotlib import colors as mcolors\r\n",
    "import scipy.sparse as sp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def preprocess_dataset(dataset):\r\n",
    "    dataset = dataset.iloc[dataset.date_created_at.dropna().index]\r\n",
    "    dataset['date_index'] = pd.to_datetime(dataset.date_created_at, errors='coerce')\r\n",
    "    dataset = dataset.loc[dataset['date_index'].dropna().index]\r\n",
    "    \r\n",
    "    datasetusers = []\r\n",
    "\r\n",
    "    for mdate, df in dataset.groupby(pd.Grouper(key='date_index', freq='d')):\r\n",
    "        datasetusers.append(df.loc[df.user_id.drop_duplicates().index])\r\n",
    "\r\n",
    "    return pd.concat(datasetusers)\r\n",
    "\r\n",
    "def Map(func, lst):\r\n",
    "    return list(map(func, lst))\r\n",
    "\r\n",
    "def Filter(func, lst):\r\n",
    "    return list(filter(func, lst))\r\n",
    "\r\n",
    "def Enumerate(lst):\r\n",
    "    return list(enumerate(lst))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def get_data_between(dataset, mindate, maxdate):\r\n",
    "    lowerbound = dataset[dataset.date_index > mindate]\r\n",
    "    return lowerbound[lowerbound.date_index < maxdate]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import nltk\r\n",
    "nltk.download('stopwords')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alxau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "tokenizer = TweetTokenizer()\r\n",
    "\r\n",
    "sw = stopwords.words('english')\r\n",
    "\r\n",
    "sw = sw + [',', '.', '!', '?', '’', '‘', '(', ')', '”', '“', '@', '/', '-']\r\n",
    "\r\n",
    "def transform_social_text(sentences, lower=True):\r\n",
    "    hashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\r\n",
    "    mentions = re.compile(r\"^@\\S+|\\s@\\S+\")\r\n",
    "    urls = re.compile(r\"https?://\\S+\")\r\n",
    "\r\n",
    "    def process_text(text):\r\n",
    "        if lower:\r\n",
    "            text = text.lower()\r\n",
    "        text = hashtags.sub('', text)\r\n",
    "        text = mentions.sub('', text)\r\n",
    "        text = urls.sub('', text)\r\n",
    "        text = text.replace('\\n', ' .')\r\n",
    "\r\n",
    "        return text.strip()\r\n",
    "    \r\n",
    "    return list(map(process_text, sentences))\r\n",
    "\r\n",
    "def tokenize_tweet(tweet):\r\n",
    "    word_tokens = tokenizer.tokenize(tweet)\r\n",
    "    word_tokens = [w for w in word_tokens if not w in sw]\r\n",
    "    return word_tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "def traing_cluster_algo(data, K, iterations):\r\n",
    "    mgp = MovieGroupProcess(K=K, alpha=0.1, beta=0.1, n_iters=iterations)\r\n",
    "    mgp.fit(data, 1000)\r\n",
    "    return mgp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "def get_vocabularies(tokens):\r\n",
    "    cc = Counter()\r\n",
    "    for lst in tokens:\r\n",
    "        cc.update(lst)\r\n",
    "\r\n",
    "    vocab = dict([(i, v) for i, v in list(enumerate(map(lambda x :x[0], cc.most_common())))[:10000]])\r\n",
    "    \r\n",
    "    ## Add Unk Token\r\n",
    "    vocab[len(vocab)] = '$$unk$$'\r\n",
    "    \r\n",
    "    reverse_vocab = dict([(v , i) for i, v in vocab.items()])\r\n",
    "    return vocab, reverse_vocab, '$$unk$$'\r\n",
    "\r\n",
    "# Get Cluster numbers by date\r\n",
    "def get_cluster_timeseries(df, mdf):\r\n",
    "    timeseries = pd.merge(mdf['cluster'], df[['date_created_at']], how='left', left_index=True, right_index=True)\r\n",
    "    return timeseries\r\n",
    "    \r\n",
    "'''\r\n",
    "Returns a tuple of \r\n",
    "    (cluster_size,\r\n",
    "    cluster_id, \r\n",
    "    topwords,\r\n",
    "    most representative tweet, \r\n",
    "    avg engagement,\r\n",
    "    avg followers, \r\n",
    "    score)\r\n",
    "'''\r\n",
    "def addClusterMetrics(size2cluster, clusters, df, tweets_indexes, tweet_tokens):\r\n",
    "    mdf = pd.DataFrame([(mid, np.argmax(clusters.score(doc)), max(clusters.score(doc)), doc) for mid, doc in zip(tweets_indexes, tweet_tokens)])\r\n",
    "    mdf = mdf.set_index([0])\r\n",
    "    mdf.columns = ['cluster', 'score', 'text']\r\n",
    "    \r\n",
    "    # Cluster Id x Date\r\n",
    "    timeseries = get_cluster_timeseries(df, mdf)\r\n",
    "   \r\n",
    "    # Get Centroids (tweets)\r\n",
    "    result = pd.merge(mdf, df[['text', 'score_engagement', 'counts_followers']], how='left', left_index=True, right_index=True)\r\n",
    "    # Aggregate data by cluster (by avg)\r\n",
    "    aggregations = result.fillna(0).groupby('cluster').mean()\r\n",
    "    idx = result.groupby(['cluster'])['score'].transform(max) == mdf['score']\r\n",
    "    rr = result[idx].groupby(['cluster']).first()\r\n",
    "    centroids = pd.merge(aggregations, rr, how='left', on='cluster')['text_y']\r\n",
    "    \r\n",
    "    # Get cluster ids\r\n",
    "    cluster_numbers = mdf['cluster'].unique()\r\n",
    "    cluster_numbers.sort()\r\n",
    "    \r\n",
    "    return list(zip(map(lambda x:x[0], size2cluster), \r\n",
    "             cluster_numbers,\r\n",
    "             [\" \".join([w for w, s in lst]) for lst in map(lambda x:x[1], size2cluster)],\r\n",
    "             centroids,\r\n",
    "             aggregations['score_engagement'], \r\n",
    "             aggregations['counts_followers'],\r\n",
    "             (1 + aggregations['score_engagement']) * np.array(list(map(lambda x:x[0], size2cluster)))  )), timeseries\r\n",
    "\r\n",
    "\r\n",
    "'''Returns cluster aggregated data and the volume timeseries of clusters'''\r\n",
    "def extract_cluster(mgp, dataset, topk, tweets_indexes, tweet_tokens, order_pos=4):\r\n",
    "    \r\n",
    "    doc_count = mgp.cluster_doc_count\r\n",
    "    word_distribution = [\r\n",
    "        sorted(list(cluster.items()), key=lambda x: x[1], reverse=True)[:topk]\r\n",
    "        for cluster in mgp.cluster_word_distribution\r\n",
    "    ]\r\n",
    "    \r\n",
    "    \r\n",
    "    size2cluster = [(d, w) for d, w in zip(doc_count, word_distribution) if d > 0]\r\n",
    "    print(mgp.cluster_doc_count)\r\n",
    "    size2cluster, timeseries = addClusterMetrics(size2cluster, mgp, dataset, tweets_indexes, tweet_tokens)\r\n",
    "    size2cluster = sorted(size2cluster, key=lambda x: x[order_pos], reverse=True)\r\n",
    "    \r\n",
    "    return size2cluster, timeseries\r\n",
    "\r\n",
    "\r\n",
    "'''\r\n",
    "Compute the cluster algorithm on a dataset\r\n",
    "\r\n",
    "Parameters:\r\n",
    "    dataset: kpi6 dataset\r\n",
    "    minddate: from date\r\n",
    "    maxdate: to date\r\n",
    "    K: # cluster upper bound\r\n",
    "    iterations: of the clustering algorithm\r\n",
    "    topk: most representative words\r\n",
    "    order_pos: sort result by position of the tuple in the result\r\n",
    "    \r\n",
    "Returns:\r\n",
    "    cluster_aggregated_data (see #addClusterMetrics)\r\n",
    "    timeseries (see #get_cluster_timeseries)\r\n",
    "    cluster algorithm object\r\n",
    "'''\r\n",
    "def compute_clusters_between_dates(dataset, mindate, maxdate,\r\n",
    "                                   K, iterations, topk, order_pos = 4):\r\n",
    "    \r\n",
    "    selecteddata = get_data_between(dataset, mindate, maxdate)\r\n",
    "    tweets_indexes = selecteddata.text.dropna().index\r\n",
    "\r\n",
    "    processedtweets = transform_social_text(selecteddata.text.dropna())\r\n",
    "    processedtweets = [tokenize_tweet(tweet) for tweet in processedtweets]\r\n",
    "    processedtweets = list(filter(lambda x: len(x[1]) > 0, zip(tweets_indexes, processedtweets)))\r\n",
    "\r\n",
    "    tweets_indexes = list(map(lambda x:x[0], processedtweets))\r\n",
    "    tweet_tokens = list(map(lambda x:x[1], processedtweets))\r\n",
    "    \r\n",
    "    vocab, reverse_vocab, unk = get_vocabularies(tweet_tokens)\r\n",
    "    \r\n",
    "    clusters = traing_cluster_algo(tweet_tokens, K, iterations)\r\n",
    "    \r\n",
    "    aggregated_data, timeseries = extract_cluster(clusters, dataset, topk, tweets_indexes, tweet_tokens, order_pos)\r\n",
    "    \r\n",
    "    return aggregated_data, timeseries, clusters, ( vocab, reverse_vocab, unk), tweet_tokens"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "def init_bottom(bottom, df):\r\n",
    "    for i in df.index:\r\n",
    "        if i not in bottom:\r\n",
    "            bottom[i] = 0\r\n",
    "\r\n",
    "def get_x_y(indexes, vals, bottom):\r\n",
    "    keys = sorted(list(bottom.keys()))\r\n",
    "    \r\n",
    "    vals = [vals[i] if i in indexes else 0 for i in keys]\r\n",
    "    return pd.DatetimeIndex(keys), vals\r\n",
    "\r\n",
    "def update_bottom(bottom, bottom_df):\r\n",
    "    for ix in bottom_df.index:\r\n",
    "        bottom[ix] += bottom_df.loc[ix]['val']\r\n",
    "        \r\n",
    "\r\n",
    "def get_bottom_series(bottom):\r\n",
    "    keys = sorted(list(bottom.keys()))\r\n",
    "    return [bottom[k] for k in keys]\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def get_timeseries(series):\r\n",
    "    %matplotlib inline\r\n",
    "    seriesc = series.copy()\r\n",
    "    seriesc['val'] = 1\r\n",
    "\r\n",
    "    seriesc['date_index'] =  pd.to_datetime(seriesc.date_created_at,  errors='coerce')\r\n",
    "\r\n",
    "    ts = seriesc.groupby(['cluster', pd.Grouper(key='date_index', freq='d')]).count()\r\n",
    "    multindex = ts.index\r\n",
    "    clusters = multindex.get_level_values(0).unique()\r\n",
    "    return [ts.loc[i] for i in clusters]\r\n",
    "\r\n",
    "\r\n",
    "def print_topic_chart(series, clusters):\r\n",
    "    clusters_sorted_by_num = sorted(clusters, key=lambda x:x[1])\r\n",
    "    topwords = list(map(lambda x:\" \".join(x[2].split(' ')[:7]), clusters_sorted_by_num))\r\n",
    "    \r\n",
    "    # get index\r\n",
    "    indexes = np.argsort(list(map(lambda x:x[0], clusters_sorted_by_num)))[::-1]\r\n",
    "    \r\n",
    "    \r\n",
    "    colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\r\n",
    "\r\n",
    "    # Sort colors by hue, saturation, value and name.\r\n",
    "    by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgba(color)[:3])), name)\r\n",
    "                    for name, color in colors.items())\r\n",
    "    sorted_names = [name for hsv, name in by_hsv]\r\n",
    "    np.random.shuffle(sorted_names)\r\n",
    "\r\n",
    "    ss=get_timeseries(series)\r\n",
    "    \r\n",
    "    fig = plt.figure(figsize=(10, 8), constrained_layout=True)\r\n",
    "    axs = fig.subplots(1,1)\r\n",
    "    bottom = {}\r\n",
    "    \r\n",
    "    # get all indexes\r\n",
    "    \r\n",
    "    for i in range(len(ss)):\r\n",
    "        init_bottom(bottom, ss[i])\r\n",
    "        \r\n",
    "    for i in range(len(ss)):\r\n",
    "        plt.sca(axs)\r\n",
    "        plt.xticks(rotation=45)\r\n",
    "\r\n",
    "        axs.set_title('Volumes')\r\n",
    "        axs.grid(True)\r\n",
    "        \r\n",
    "        if i != 0:\r\n",
    "            s_indexes = ss[indexes[i]].index\r\n",
    "            \r\n",
    "            bottom_df = ss[indexes[i-1]]\r\n",
    "            update_bottom(bottom, bottom_df)\r\n",
    "            bottom_series = get_bottom_series(bottom)\r\n",
    "            X, y = get_x_y(ss[indexes[i]].index, ss[indexes[i]]['val'], bottom)\r\n",
    "            \r\n",
    "            axs.bar(X, y, bottom=bottom_series, color=sorted_names[indexes[i]])\r\n",
    "        else:\r\n",
    "            X, y = get_x_y(ss[indexes[i]].index, ss[indexes[i]]['val'], bottom)\r\n",
    "            axs.bar(X, y, color=sorted_names[indexes[i]])\r\n",
    "\r\n",
    "    axs.legend(np.array(sorted_names)[indexes], labels=np.array(topwords)[indexes], loc =\"upper left\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "with open(file='data/authority_sets.txt', mode='r') as f:\r\n",
    "    category_list = []\r\n",
    "    category = f.readline()[:-1]\r\n",
    "    category_list.append(category)\r\n",
    "    \r\n",
    "    authority_sets = {}\r\n",
    "    authority_sets[category] = []\r\n",
    "    \r\n",
    "    lines = f.readlines()\r\n",
    "    for line in lines:\r\n",
    "        if(line[0] != '@'):\r\n",
    "            if(line != '\\n'):\r\n",
    "                category = line[:-1]\r\n",
    "                category_list.append(category)\r\n",
    "                authority_sets[category] = []\r\n",
    "        else:\r\n",
    "            if(line[-1:] == '\\n'):\r\n",
    "                authority_sets[category].append(line[1:-1])\r\n",
    "            else:\r\n",
    "                authority_sets[category].append(line[1:])\r\n",
    "\r\n",
    "for i in authority_sets:\r\n",
    "    print(i, authority_sets[i])\r\n",
    "\r\n",
    "categories = Enumerate(category_list)\r\n",
    "print(categories)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Politici ['matteosalvinimi', 'GiorgiaMeloni', 'EnricoLetta ', 'nzingaretti ', 'MonicaCirinna ', 'elenabonetti', 'matteorenzi', 'RossellaMuroni', 'luigidimaio', 'ale_dibattista', 'beppe_grillo', 'GiuseppeConteIT', 'NFratoianni', 'pbersani', 'pdnetwork', 'bobogiac', 'gasparripdl ', 'FratellidItalia', 'LegaSalvini', 'Capezzone', 'borghi_claudio', 'berlusconi', 'forza_italia', 'DarioNardella', 'carlaruocco1', 'gualtierieurope', 'BeaLorenzin', 'robersperanza', 'dariofrance', 'DaniloToninelli', 'BeppeSala', 'ellyesse', 'ElioLannutti', 'sbonaccini', 'marcocappato', 'PietroGrasso', 'ItaliaViva', 'zaiapresidente', 'TeresaBellanova', 'Azione_it', 'GuidoCrosetto', 'gparagone']\n",
      "Esperti di settore e giornalisti ['DarioBressanini', 'sabri_giannini', 'RudyBandiera', 'la_kuzzo', 'M_gabanelli', 'robertosaviano', 'petergomezblog', 'corradoformigli', 'IaconaRiccardo', 'marcotravaglio', 'AndreaScanzi', 'lucatelese', 'stanzaselvaggia', 'concitadeg', 'giucruciani', 'mariogiordano5', 'Tommasolabate', 'DAVIDPARENZO', 'myrtamerlino', 'alesallusti', 'NicolaPorro', 'BelpietroTweet', 'BrunoVespa', 'PaoloDebbio', 'GilettiMassimo', 'lucasofri', 'dariabig', 'divagatrice', 'RobiVil', 'distefanovalori']\n",
      "ONG&leaders ['Legambiente', 'Greenpeace_ITA', 'SaveChildrenIT', 'UNICEF_Italia', 'amnestyitalia', 'WWFitalia', 'StefanoCiafani', 'ap_legambiente', 'donabianchi1', 'ActionAidItalia', 'Fondoambiente', 'Italia_Nostra', 'FranFerrante', 'Kyoto_Club', 'robdellaseta', 'GiaSilvestrini', 'gonufrio']\n",
      "Sindacati e leader ['cgilnazionale', 'fiomnet', 'UILofficial', 'flaicgil', 'filleacgil', 'mauriziolandini', 'CislNazionale', 'FurlanAnnamaria', 'PpBombardieri', 'SusannaCamusso', 'fai_cisl', 'UGLConf']\n",
      "Influencer ['camillamendini', 'tessagelisio', 'LuciaCuffaro', 'MarcoBianchiOff', 'Link4Universe', 'Fedez', 'ChiaraFerragni', 'MarroneEmma', 'noemiofficial', 'chiarabiasi', 'VeronicaFerraro', 'andreadelogu', 'emastokholma', 'pif_iltestimone', 'federusso80', 'LucaBizzarri']\n",
      "programmi radio  e tv ['LaZanzaraR24', 'reportrai3', 'PiazzapulitaLA7', 'redazioneiene', 'Cartabiancarai3', 'mimandaRai3', 'Drittorovescio_', 'OttoemezzoTW', 'agorarai', 'Ariachetira', 'OmnibusLa7', 'welikeduel', 'QRepubblica', 'fuoridalcorotv', 'nonelarena', 'ChiVieneACena3']\n",
      "Associazioni e consorzi ['adocnazionale', 'MovConsumatori', 'adiconsum', 'consumatori', 'HelpConsumatori', 'Codacons', 'fedcons', 'massidona', 'ADUC1', 'Cittadinanzatti', 'Altroconsumo', 'CarloRienzi', 'pierani', 'fedcons', 'ConsumForum', 'Assoutenti', 'consumatori', 'Corepla_Riciclo', 'comieco', 'conai', '3filetti', 'MarevivoOnlus', 'plasticfreeit']\n",
      "testate mainstrem e portali verticali ['fattoquotidiano', 'ilpost', 'ilmessaggeroit', 'repubblica', 'Corriere', 'Agenzia_Ansa', 'VITAnonprofit', 'LaStampa', 'VanityFairIt', 'ilgiornale', 'Linkiesta', '_MicroMega_', 'giornalettismo', 'MilanoFinanza', 'greenMe_it', 'Gazzettino', 'Affaritaliani', 'GDS_it', 'GQitalia', 'ansa_ambiente', 'il_piccolo', 'altreconomia', 'Lantidiplomatic', 'FattoAlimentare', 'ItaliaaTavola', 'Ecodallecitta', 'alimentandonews', 'ilSalvagenteit', 'Greenreport_it', 'SecolodItalia1', 'Qualenergiait', 'EcoEcologia', 'Valori_it', 'rinnovabiliit', 'ilGiunco', 'lamescolanza', 'wireditalia', 'Agenzia_Italia', 'alfemminile_com', 'nostrofiglio', 'PianetaMamma', 'FattoreMamma']\n",
      "[(0, 'Politici'), (1, 'Esperti di settore e giornalisti'), (2, 'ONG&leaders'), (3, 'Sindacati e leader'), (4, 'Influencer'), (5, 'programmi radio  e tv'), (6, 'Associazioni e consorzi'), (7, 'testate mainstrem e portali verticali')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# filters tweets by a subset of authorities\r\n",
    "def get_authority_tweets(auth_list, df):\r\n",
    "   return df[df['user_username'].isin(auth_list)]\r\n",
    "\r\n",
    "# filters tweets by multiple subsets of authorities and outputs their union\r\n",
    "def get_authority_tweets_multiple_categories(auth_cat_list, df):\r\n",
    "   dflist = []\r\n",
    "   for i, value in enumerate(auth_cat_list):\r\n",
    "      authority_set = authority_sets[value]\r\n",
    "      dflist.append(df[df['user_username'].isin(authority_set)])\r\n",
    "   return pd.concat(dflist).drop_duplicates()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "ferrero_corp = pd.read_csv('data/ferrero_corporate.csv') \r\n",
    "ferrero_corpnospam = preprocess_dataset(ferrero_corp)\r\n",
    "ferrero_corp_no_na = ferrero_corpnospam.copy()\r\n",
    "# ferrero_corp_no_na = ferrero_corpnospam.dropna(1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\alxau\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (1,4,44) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "<ipython-input-35-b07506d9becb>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['date_index'] = pd.to_datetime(dataset.date_created_at, errors='coerce')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "ferrero_corp_auth = get_authority_tweets_multiple_categories(category_list, ferrero_corp_no_na)\r\n",
    "ferrero_corp_auth"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        social                   id                              topic_id  \\\n",
       "34648  twitter  1174618145786650624  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "34065  twitter  1176441842096910336  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "33847  twitter  1176748033066844160  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "32534  twitter  1183821988437135362  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "32064  twitter  1186949229438263297  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "...        ...                  ...                                   ...   \n",
       "1013   twitter  1418810115445166080  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "841    twitter  1420717382830415880  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "822    twitter  1421105542945202182  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "467    twitter  1426075939201421313  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "61     twitter  1430765728890859524  7ee62d5c-5811-45ce-9cef-c09d143f041a   \n",
       "\n",
       "       rule_id is_comment                                               text  \\\n",
       "34648  12559.0      False  La Ferrero riconosce a 6000 dipendenti un prem...   \n",
       "34065  12559.0      False  Il Ministro Fioramonti si permette di giustifi...   \n",
       "33847  12559.0      False  @theoddmother @lofioramonti In Italia la Ferre...   \n",
       "32534  12559.0      False  @gianni_la_marca @angelofilippi Per il mercato...   \n",
       "32064  12559.0      False  Siamo in un pericoloso paradosso con il Paese ...   \n",
       "...        ...        ...                                                ...   \n",
       "1013   12559.0      False  Ferrero, la strategia green del big di Alba (è...   \n",
       "841    12559.0      False  Ferrero l'azienda meglio percepita sul territo...   \n",
       "822    12559.0      False  L’attimo fuggente, online il numero di agosto ...   \n",
       "467    12559.0      False  Mediobanca, Gavio arrotonda la quota. I Ferrer...   \n",
       "61     12559.0      False  Da anni le aziende alimentari prendono impegni...   \n",
       "\n",
       "      lang_value           date_created_at  counts_following  \\\n",
       "34648         it  2019-09-19T09:36:03.000Z             919.0   \n",
       "34065         it  2019-09-24T10:22:47.000Z            2192.0   \n",
       "33847         it  2019-09-25T06:39:28.000Z            2192.0   \n",
       "32534         it  2019-10-14T19:08:51.000Z            2192.0   \n",
       "32064         it  2019-10-23T10:15:23.000Z             507.0   \n",
       "...          ...                       ...               ...   \n",
       "1013          it  2021-07-24T05:47:46.000Z             262.0   \n",
       "841           it  2021-07-29T12:06:34.000Z              15.0   \n",
       "822           it  2021-07-30T13:48:58.000Z             424.0   \n",
       "467           it  2021-08-13T06:59:33.000Z             520.0   \n",
       "61            it  2021-08-26T05:35:06.000Z            1294.0   \n",
       "\n",
       "       counts_followers  ...  counts_likes  score_engagement       user_id  \\\n",
       "34648         1115932.0  ...        4649.0          0.519143  1.305370e+08   \n",
       "34065          156189.0  ...        3477.0          3.001747  4.139162e+08   \n",
       "33847          156189.0  ...           3.0          0.001920  4.139162e+08   \n",
       "32534          156189.0  ...           0.0          0.000000  4.139162e+08   \n",
       "32064          181802.0  ...          35.0          0.021880  1.351476e+07   \n",
       "...                 ...  ...           ...               ...           ...   \n",
       "1013          2395017.0  ...           7.0          0.000493  3.952189e+08   \n",
       "841            110805.0  ...           7.0          0.007394  2.996339e+07   \n",
       "822              3360.0  ...           0.0          0.000000  5.459782e+08   \n",
       "467             68044.0  ...           0.0          0.001761  3.552595e+07   \n",
       "61               5081.0  ...           0.0          0.000000  3.159339e+09   \n",
       "\n",
       "        user_username                         user_name  \\\n",
       "34648   GiorgiaMeloni               Giorgia Meloni ?? ن   \n",
       "34065   GuidoCrosetto                    Guido Crosetto   \n",
       "33847   GuidoCrosetto                    Guido Crosetto   \n",
       "32534   GuidoCrosetto                    Guido Crosetto   \n",
       "32064     LegaSalvini            Lega - Salvini Premier   \n",
       "...               ...                               ...   \n",
       "1013         Corriere               Corriere della Sera   \n",
       "841     MilanoFinanza                     MilanoFinanza   \n",
       "822      lamescolanza  L'attimo fuggente - Lamescolanza   \n",
       "467     Affaritaliani                  Affaritaliani.it   \n",
       "61     ilSalvagenteit                     il Salvagente   \n",
       "\n",
       "                                    user_profile_picture  user_gender_value  \\\n",
       "34648  https://pbs.twimg.com/profile_images/113404761...             female   \n",
       "34065  https://pbs.twimg.com/profile_images/136781770...               male   \n",
       "33847  https://pbs.twimg.com/profile_images/136781770...               male   \n",
       "32534  https://pbs.twimg.com/profile_images/136781770...               male   \n",
       "32064  https://pbs.twimg.com/profile_images/943884100...            unknown   \n",
       "...                                                  ...                ...   \n",
       "1013   https://pbs.twimg.com/profile_images/134684048...            unknown   \n",
       "841    https://pbs.twimg.com/profile_images/132867798...            unknown   \n",
       "822    https://pbs.twimg.com/profile_images/204189121...            unknown   \n",
       "467    https://pbs.twimg.com/profile_images/135000774...            unknown   \n",
       "61     https://pbs.twimg.com/profile_images/833679361...            unknown   \n",
       "\n",
       "      user_lang_source user_verified                date_index  \n",
       "34648         provided           1.0 2019-09-19 09:36:03+00:00  \n",
       "34065         provided           0.0 2019-09-24 10:22:47+00:00  \n",
       "33847         provided           0.0 2019-09-25 06:39:28+00:00  \n",
       "32534         provided           0.0 2019-10-14 19:08:51+00:00  \n",
       "32064         provided           1.0 2019-10-23 10:15:23+00:00  \n",
       "...                ...           ...                       ...  \n",
       "1013          provided           1.0 2021-07-24 05:47:46+00:00  \n",
       "841           provided           0.0 2021-07-29 12:06:34+00:00  \n",
       "822           provided           0.0 2021-07-30 13:48:58+00:00  \n",
       "467           provided           1.0 2021-08-13 06:59:33+00:00  \n",
       "61            provided           0.0 2021-08-26 05:35:06+00:00  \n",
       "\n",
       "[283 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>social</th>\n",
       "      <th>id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>rule_id</th>\n",
       "      <th>is_comment</th>\n",
       "      <th>text</th>\n",
       "      <th>lang_value</th>\n",
       "      <th>date_created_at</th>\n",
       "      <th>counts_following</th>\n",
       "      <th>counts_followers</th>\n",
       "      <th>...</th>\n",
       "      <th>counts_likes</th>\n",
       "      <th>score_engagement</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_username</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_profile_picture</th>\n",
       "      <th>user_gender_value</th>\n",
       "      <th>user_lang_source</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34648</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1174618145786650624</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>La Ferrero riconosce a 6000 dipendenti un prem...</td>\n",
       "      <td>it</td>\n",
       "      <td>2019-09-19T09:36:03.000Z</td>\n",
       "      <td>919.0</td>\n",
       "      <td>1115932.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4649.0</td>\n",
       "      <td>0.519143</td>\n",
       "      <td>1.305370e+08</td>\n",
       "      <td>GiorgiaMeloni</td>\n",
       "      <td>Giorgia Meloni ?? ن</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/113404761...</td>\n",
       "      <td>female</td>\n",
       "      <td>provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-09-19 09:36:03+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34065</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1176441842096910336</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Il Ministro Fioramonti si permette di giustifi...</td>\n",
       "      <td>it</td>\n",
       "      <td>2019-09-24T10:22:47.000Z</td>\n",
       "      <td>2192.0</td>\n",
       "      <td>156189.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>3.001747</td>\n",
       "      <td>4.139162e+08</td>\n",
       "      <td>GuidoCrosetto</td>\n",
       "      <td>Guido Crosetto</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/136781770...</td>\n",
       "      <td>male</td>\n",
       "      <td>provided</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-09-24 10:22:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33847</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1176748033066844160</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>@theoddmother @lofioramonti In Italia la Ferre...</td>\n",
       "      <td>it</td>\n",
       "      <td>2019-09-25T06:39:28.000Z</td>\n",
       "      <td>2192.0</td>\n",
       "      <td>156189.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>4.139162e+08</td>\n",
       "      <td>GuidoCrosetto</td>\n",
       "      <td>Guido Crosetto</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/136781770...</td>\n",
       "      <td>male</td>\n",
       "      <td>provided</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-09-25 06:39:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32534</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1183821988437135362</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>@gianni_la_marca @angelofilippi Per il mercato...</td>\n",
       "      <td>it</td>\n",
       "      <td>2019-10-14T19:08:51.000Z</td>\n",
       "      <td>2192.0</td>\n",
       "      <td>156189.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.139162e+08</td>\n",
       "      <td>GuidoCrosetto</td>\n",
       "      <td>Guido Crosetto</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/136781770...</td>\n",
       "      <td>male</td>\n",
       "      <td>provided</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-14 19:08:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32064</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1186949229438263297</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Siamo in un pericoloso paradosso con il Paese ...</td>\n",
       "      <td>it</td>\n",
       "      <td>2019-10-23T10:15:23.000Z</td>\n",
       "      <td>507.0</td>\n",
       "      <td>181802.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.021880</td>\n",
       "      <td>1.351476e+07</td>\n",
       "      <td>LegaSalvini</td>\n",
       "      <td>Lega - Salvini Premier</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/943884100...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-10-23 10:15:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1418810115445166080</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Ferrero, la strategia green del big di Alba (è...</td>\n",
       "      <td>it</td>\n",
       "      <td>2021-07-24T05:47:46.000Z</td>\n",
       "      <td>262.0</td>\n",
       "      <td>2395017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>3.952189e+08</td>\n",
       "      <td>Corriere</td>\n",
       "      <td>Corriere della Sera</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/134684048...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-07-24 05:47:46+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1420717382830415880</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Ferrero l'azienda meglio percepita sul territo...</td>\n",
       "      <td>it</td>\n",
       "      <td>2021-07-29T12:06:34.000Z</td>\n",
       "      <td>15.0</td>\n",
       "      <td>110805.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>2.996339e+07</td>\n",
       "      <td>MilanoFinanza</td>\n",
       "      <td>MilanoFinanza</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/132867798...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>provided</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-07-29 12:06:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1421105542945202182</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>L’attimo fuggente, online il numero di agosto ...</td>\n",
       "      <td>it</td>\n",
       "      <td>2021-07-30T13:48:58.000Z</td>\n",
       "      <td>424.0</td>\n",
       "      <td>3360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.459782e+08</td>\n",
       "      <td>lamescolanza</td>\n",
       "      <td>L'attimo fuggente - Lamescolanza</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/204189121...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>provided</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-07-30 13:48:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1426075939201421313</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mediobanca, Gavio arrotonda la quota. I Ferrer...</td>\n",
       "      <td>it</td>\n",
       "      <td>2021-08-13T06:59:33.000Z</td>\n",
       "      <td>520.0</td>\n",
       "      <td>68044.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>3.552595e+07</td>\n",
       "      <td>Affaritaliani</td>\n",
       "      <td>Affaritaliani.it</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/135000774...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>provided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-08-13 06:59:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>twitter</td>\n",
       "      <td>1430765728890859524</td>\n",
       "      <td>7ee62d5c-5811-45ce-9cef-c09d143f041a</td>\n",
       "      <td>12559.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Da anni le aziende alimentari prendono impegni...</td>\n",
       "      <td>it</td>\n",
       "      <td>2021-08-26T05:35:06.000Z</td>\n",
       "      <td>1294.0</td>\n",
       "      <td>5081.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.159339e+09</td>\n",
       "      <td>ilSalvagenteit</td>\n",
       "      <td>il Salvagente</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/833679361...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>provided</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-08-26 05:35:06+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 24 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "ferrero_corp_auth.to_csv('data/authority_filtered/ferrero_corp_auth.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# istante in cui gli utenti hanno tweettato, e variazione di volume nel periodo immediatamente adiacente\r\n",
    "# "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "ferrero_corp_spikes = pd.read_csv('data/ferrero_corporate_spikes.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "ferrero_corp_authority_spikes"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ferrero_corp_authority_spikes' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-9aaeec205568>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mferrero_corp_authority_spikes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ferrero_corp_authority_spikes' is not defined"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "f446ed4898e137face024438143ad86cf21c8cccb3ccfa44cb119e4a51b03028"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}